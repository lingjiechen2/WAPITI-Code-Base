{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/remote-home/miintern1/anaconda3/envs/watermark/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/remote-home/miintern1/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/remote-home/miintern1/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformers import AutoModelForCausalLM\n",
    "import os\n",
    "import json\n",
    "os.environ['http_proxy'] = \"http://10.176.52.116:7890\"\n",
    "os.environ['https_proxy'] = \"http://10.176.52.116:7890\"\n",
    "os.environ['all_proxy'] = \"socks5://10.176.52.116:7891\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster comprises IBM's Opteron-based eServer 325 server and systems management software and storage devices that can run Linux and Windows operating systems.IBM on Tuesday announced a prepackaged and pretested cluster that is powered by Advanced Micro Devices Inc.s 64-bit Opteron processor.IBM, of Armonk, N.Y., is combining its Opteron-based eServer 325 server—which targets scientific and technical computing users—with systems management software and storage devices to offer a bundled package that can run Linux and Windows operating systems.The new offering, which will be available later this month or in early December, is part of IBMs eServer Cluster 1350, which also includes bundles based on the companys BladeCenter blade servers and two-processor x335 and x345 systems using Intel Corp.s 32-bit Xeon chips.Clusters comprise multiple servers tied together to create a supercomputing environment for users. In a related move, IBM last week announced that it was teaming with Corning Inc., the U.S. Department of Energy and the National Nuclear Security Administration to develop high-speed, optically switched interconnects for supercomputers. The $20 million, two-and-a-half-year project is aimed at increasing network bandwidth by 50 times while at the same time cutting the costs of supercomputers.IBMs 325 systems, powered by 2GHz Opterons, give users a chance to run both their 32-bit and 64-bit applications on a single platform, which is important for mixed-use environments, said David Turek, vice president of IBMs Deep Computing unit.\"For many of these users, who have been left with a stark choice—you either run 32-bit or 64-bit—Opteron is an interesting bridge between the two,\" Turek said. \"Its an attractive proposition.\"AMD, of Sunnyvale, Calif., has pushed Opterons ability to run 32-bit applications as well as it does 64-bit applications as a key differentiator between it and Intels Itanium architecture. The 64-bit Itanium chip maintains a limited amount of backward compatibility, which means that it does not run the 32-bit applications as well as it does the 64-bit software.With the latest Itanium 2 released this summer, officials with Intel, of Santa Clara, Calif., were promoting the companys IA-32 Execution Layer, designed to bridge that performance gap. Intel, which has pushed Xeon-based systems for 32-bit applications and Itanium for 64-bit computing, views the execution layer as a way of helping customers who want to move to 64-bit computing but still have older 32-bit applications running.On Monday, Intel officials said that a software update from Microsoft Corp. that includes the execution layer for Windows applications has been delayed until the second half of next year. However, they said that Linux vendors, including Red Hat Inc. and SuSE Linux AG, both are incorporating the execution layer code in their offerings./zimages/3/28571.gifRead \"MS Delay Hinders Itanium Software Upgrade.\"Gordon Haff, an analyst with Illuminata Inc., said Opterons adoption path is mirroring that of the older Itanium technology.\"Theres a lot of interest in Opteron in [the high-performance computing space]; its nearly exclusively in HPC,\" said Haff, in Nashua, N.H. \"Its a good performing chip, and thats pretty much what HPC [customers are] looking for.\"While backward compatibility with 32-bit applications may make Opteron more attractive in the commercial space, HPC users are more interested in performance, he said.Turek agreed. \"The Intel name carries a lot of weight in the industry,\" he said. That said, HPC and technical computing customers tend to be among the early adopters of new technology.\"Theyre searching for the best technology without so much regard for the brand,\" he said.The Opteron cluster offering includes IBM Cluster Management Software, which aims to avoid problems and speed up the resolution of problems that do occur by automating repetitive tasks and error detection.Also included in the cluster package is a new Linux Cluster Install Tool, which automates much of the installation work, IBM officials said.In the supercomputing interconnect project, Cornings Science & Technology Division, in Corning, N.Y., will create a prototype for an optically switched interconnect. IBM Research Labs in the United States and Switzerland will build the systems electronic control and monitoring circuitry.\n",
      "\n",
      "The cluster includes IBM's eServer 325 server, which utilizes the Opteron processor from Advanced Micro Devices Inc., and is equipped with systems management software and storage solutions capable of supporting both Linux and Windows operating systems. IBM announced on Tuesday that it is launching a preconfigured and pretested cluster powered by the 64-bit Opteron processor. The Armonk, N.Y.-based IBM is merging its Opteron-based eServer 325 server, aimed at scientific and technical computing users, with systems management software and storage devices into a comprehensive package capable of operating on Linux and Windows platforms. This new package, set to be available later this month or in early December, is part of IBM's eServer Cluster 1350, which also features bundles that include the company's BladeCenter blade servers and dual-processor x335 and x345 systems that utilize Intel Corp.'s 32-bit Xeon processors. Clusters consist of multiple servers connected to form a supercomputing environment for users. In a related development, IBM recently announced a collaboration with Corning Inc., the U.S. Department of Energy, and the National Nuclear Security Administration to develop high-speed, optically switched interconnects for supercomputers. This project, valued at $20 million and spanning two and a half years, aims to increase network bandwidth by 50 times while simultaneously reducing the costs of supercomputers. IBM's 325 systems, equipped with 2GHz Opterons, allow users to operate both 32-bit and 64-bit applications on a single platform, which is crucial for mixed-use environments, according to David Turek, vice president of IBM's Deep Computing unit. Turek highlighted that for many users faced with the decision of running either 32-bit or 64-bit applications, Opteron serves as a valuable intermediary. AMD, based in Sunnyvale, Calif., has emphasized Opteron's capability to efficiently run both 32-bit and 64-bit applications, distinguishing it from Intel's Itanium architecture, which offers limited backward compatibility and does not perform as well with 32-bit applications as it does with 64-bit applications. With the recent release of Itanium 2 this summer, Intel officials have been promoting the IA-32 Execution Layer, which is designed to close the performance gap. Intel views this execution layer as a solution for customers transitioning to 64-bit computing while still operating older 32-bit applications. Intel officials also noted that a software update from Microsoft Corp., which includes the execution layer for Windows applications, has been postponed until the latter half of next year. However, they mentioned that Linux vendors, including Red Hat Inc. and SuSE Linux AG, are integrating the execution layer code into their products. Gordon Haff, an analyst with Illuminata Inc., observed that the adoption trajectory of Opteron is similar to that of the older Itanium technology. Haff noted that there is significant interest in Opteron within the high-performance computing (HPC) sector, where performance is the primary concern. While backward compatibility with 32-bit applications may enhance Opteron's appeal in the commercial market, HPC users prioritize performance. Turek concurred, acknowledging the influence of the Intel brand in the industry. However, he pointed out that HPC and technical computing customers are often early adopters of new technologies, focusing more on the technology itself rather than the brand. The Opteron cluster package includes IBM Cluster Management Software, designed to prevent issues and expedite problem resolution by automating repetitive tasks and error detection. The package also features a new Linux Cluster Install Tool, which simplifies much of the installation process, according to IBM officials. In the supercomputing interconnect project, Corning's Science & Technology Division, located in Corning, N.Y., will develop a prototype for an optically switched interconnect. IBM Research Labs in the United States and Switzerland will construct the system's electronic control and monitoring circuitry.\n"
     ]
    }
   ],
   "source": [
    "with open(\"/remote-home/miintern1/watermark-learnability/data/c4/paraphrased_results.json\",\"r\") as f:\n",
    "    data = json.load(f)\n",
    "original_text = data['original_text']\n",
    "paraphrased_text = data['paraphrased_text']\n",
    "for a,b in zip(original_text,paraphrased_text):\n",
    "    print(a.replace('\\n', ''))\n",
    "    print(\"\")\n",
    "    print(b)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hf_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta-llama/Llama-2-7b-hf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# , local_files_only=True\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m HookedTransformer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLlama-2-7b\u001b[39m\u001b[38;5;124m'\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, hf_model\u001b[38;5;241m=\u001b[39mhf_model)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/modeling_utils.py:3838\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3829\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3831\u001b[0m     (\n\u001b[1;32m   3832\u001b[0m         model,\n\u001b[1;32m   3833\u001b[0m         missing_keys,\n\u001b[1;32m   3834\u001b[0m         unexpected_keys,\n\u001b[1;32m   3835\u001b[0m         mismatched_keys,\n\u001b[1;32m   3836\u001b[0m         offload_index,\n\u001b[1;32m   3837\u001b[0m         error_msgs,\n\u001b[0;32m-> 3838\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3845\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3846\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3849\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3850\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3855\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3857\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   3858\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/modeling_utils.py:4317\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001b[0m\n\u001b[1;32m   4315\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4317\u001b[0m     error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4319\u001b[0m \u001b[38;5;66;03m# force memory release\u001b[39;00m\n\u001b[1;32m   4320\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "File \u001b[0;32m~/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/modeling_utils.py:711\u001b[0m, in \u001b[0;36m_load_state_dict_into_model\u001b[0;34m(model_to_load, state_dict, start_prefix)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m             load(child, state_dict, prefix \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 711\u001b[0m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_prefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# Delete `state_dict` so it could be collected by GC earlier. Note that `state_dict` is a copy of the argument, so\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# it's safe to delete it.\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "File \u001b[0;32m~/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/modeling_utils.py:709\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 709\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/modeling_utils.py:709\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 709\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping similar frames: _load_state_dict_into_model.<locals>.load at line 709 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/modeling_utils.py:709\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 709\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/watermark/lib/python3.11/site-packages/transformers/modeling_utils.py:705\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix)\u001b[0m\n\u001b[1;32m    703\u001b[0m                     module\u001b[38;5;241m.\u001b[39m_load_from_state_dict(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_from_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/watermark/lib/python3.11/site-packages/torch/nn/modules/module.py:2075\u001b[0m, in \u001b[0;36mModule._load_from_state_dict\u001b[0;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m             \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, input_param)\n\u001b[1;32m   2074\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2075\u001b[0m             \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m   2077\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mswapping\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_swap_tensors \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopying\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\") # , local_files_only=True\n",
    "model = HookedTransformer.from_pretrained('Llama-2-7b', device=\"cpu\", hf_model=hf_model)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003802776336669922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc574c715584a319234ea6379d26595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model Llama-2-7b into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HookedTransformer(\n",
       "  (embed): Embed()\n",
       "  (hook_embed): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0-31): 32 x TransformerBlock(\n",
       "      (ln1): RMSNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2): RMSNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "        (hook_rot_k): HookPoint()\n",
       "        (hook_rot_q): HookPoint()\n",
       "      )\n",
       "      (mlp): GatedMLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_pre_linear): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_attn_in): HookPoint()\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_mlp_in): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       "  (ln_final): RMSNormPre(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\") # , local_files_only=True\n",
    "model = HookedTransformer.from_pretrained('Llama-2-7b', device=\"cpu\", hf_model=hf_model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized results= [[2448, 3631, 14379, 508, 367, 8072, 11098, 29892, 1235, 29915, 29879, 437, 372, 29991]]\n",
      "recovered_text=[\"Neural networks can be fully understood, let's do it!\"]\n"
     ]
    }
   ],
   "source": [
    "example_text = \"Neural networks can be fully understood, let's do it!\"\n",
    "input_ids = model.to_tokens(example_text, prepend_bos=False)\n",
    "print('tokenized results=', input_ids.cpu().tolist())\n",
    "\n",
    "recovered_text = model.to_string(input_ids)\n",
    "print(f'{recovered_text=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hf_logits=tensor([[[ -9.6888,  -8.8738,  -0.5533,  ...,  -4.8996,  -7.5351,  -6.8189],\n",
      "         [ -9.6327, -11.9659,   2.7874,  ...,  -5.6774,  -6.4354,  -6.6760],\n",
      "         [-11.1112,  -8.2295,   3.7166,  ...,  -8.4757, -10.3463,  -7.2617],\n",
      "         ...,\n",
      "         [ -9.6158, -10.8697,   3.3311,  ...,  -6.4159,  -7.0471,  -8.4679],\n",
      "         [ -8.2840,  -6.8188,   6.9874,  ...,  -5.6472,  -7.1894,  -6.3354],\n",
      "         [-13.4876,  -9.3282,   5.1343,  ...,  -7.3542,  -8.0036,  -7.1162]]])\n",
      "logits=tensor([[[-5.4101, -4.5952,  3.7253,  ..., -0.6210, -3.2565, -2.5403],\n",
      "         [-5.1830, -7.5161,  7.2371,  ..., -1.2276, -1.9857, -2.2262],\n",
      "         [-5.2665, -2.3849,  9.5612,  ..., -2.6310, -4.5016, -1.4170],\n",
      "         ...,\n",
      "         [-5.7547, -7.0086,  7.1922,  ..., -2.5547, -3.1860, -4.6068],\n",
      "         [-5.4391, -3.9739,  9.8322,  ..., -2.8024, -4.3446, -3.4905],\n",
      "         [-6.6385, -2.4791, 11.9834,  ..., -0.5050, -1.1544, -0.2671]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hf_logits = hf_model(input_ids)['logits']\n",
    "logits, cache = model.run_with_cache(input_ids, return_type='logits')\n",
    "\n",
    "print(f'{hf_logits=}')\n",
    "print(f'{logits=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/remote-home/miintern1/watermark-learnability/data/c4/paraphrased_results.json\",\"r\") as f:\n",
    "    raw_input = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_input['original_text'])\n",
    "len(raw_input['paraphrased_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_cache_analysis(original_input):\n",
    "    original_input_ids = model.to_tokens(original_input, prepend_bos=False)\n",
    "    original_logits, original_cache = model.run_with_cache(original_input_ids, return_type='logits')\n",
    "    return original_cache, original_logits\n",
    "\n",
    "comparison_input =  \"Occasional diarrhea is a common occurrence. Most people will experience an episode of diarrhea at least once or twice a year that will disappear in a couple of days.\\nLuckily, there are many foods to eat that may help a person reduce the symptoms of diarrhea. There are also some foods to avoid when dealing with a bout of diarrhea, and some additional home care tips to consider.\\nAnyone who is experiencing persistent diarrhea should see a doctor, as a person may become dehydrated over time.\\nDiarrhea is a bowel movement that is more liquid than solid or has a loose texture. It is a common problem and may occur a couple of times each year. Diarrhea will usually last no more than 3 days.\\nSoft, bland foods, such as toast, will help to absorb excess water and ease the symptoms of diarrhea.\\nPeople with chronic digestive conditions, such as irritable bowel syndrome (IBS) or Crohn's disease, may experience diarrhea more regularly.\\nA person\"\n",
    "\n",
    "comparison_cache, comparison_logits = prompt_cache_analysis(comparison_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_input_ids = model.to_tokens(original_input, prepend_bos=False)\n",
    "paraphrased_input_ids = model.to_tokens(paraphrased_input, prepend_bos=False)\n",
    "\n",
    "original_logits, original_cache = model.run_with_cache(original_input_ids, return_type='logits')\n",
    "paraphrased_logits, paraphrased_cache = model.run_with_cache(paraphrased_input_ids, return_type='logits')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096])\n",
      "['hook_embed',\n",
      " 'blocks.0.hook_resid_pre',\n",
      " 'blocks.0.ln1.hook_scale',\n",
      " 'blocks.0.ln1.hook_normalized',\n",
      " 'blocks.0.attn.hook_q',\n",
      " 'blocks.0.attn.hook_k',\n",
      " 'blocks.0.attn.hook_v',\n",
      " 'blocks.0.attn.hook_rot_q',\n",
      " 'blocks.0.attn.hook_rot_k',\n",
      " 'blocks.0.attn.hook_attn_scores',\n",
      " 'blocks.0.attn.hook_pattern',\n",
      " 'blocks.0.attn.hook_z',\n",
      " 'blocks.0.hook_attn_out',\n",
      " 'blocks.0.hook_resid_mid',\n",
      " 'blocks.0.ln2.hook_scale',\n",
      " 'blocks.0.ln2.hook_normalized',\n",
      " 'blocks.0.mlp.hook_pre',\n",
      " 'blocks.0.mlp.hook_pre_linear',\n",
      " 'blocks.0.mlp.hook_post',\n",
      " 'blocks.0.hook_mlp_out',\n",
      " 'blocks.0.hook_resid_post',\n",
      " 'blocks.1.hook_resid_pre',\n",
      " 'blocks.1.ln1.hook_scale',\n",
      " 'blocks.1.ln1.hook_normalized',\n",
      " 'blocks.1.attn.hook_q',\n",
      " 'blocks.1.attn.hook_k',\n",
      " 'blocks.1.attn.hook_v',\n",
      " 'blocks.1.attn.hook_rot_q',\n",
      " 'blocks.1.attn.hook_rot_k',\n",
      " 'blocks.1.attn.hook_attn_scores',\n",
      " 'blocks.1.attn.hook_pattern',\n",
      " 'blocks.1.attn.hook_z',\n",
      " 'blocks.1.hook_attn_out',\n",
      " 'blocks.1.hook_resid_mid',\n",
      " 'blocks.1.ln2.hook_scale',\n",
      " 'blocks.1.ln2.hook_normalized',\n",
      " 'blocks.1.mlp.hook_pre',\n",
      " 'blocks.1.mlp.hook_pre_linear',\n",
      " 'blocks.1.mlp.hook_post',\n",
      " 'blocks.1.hook_mlp_out',\n",
      " 'blocks.1.hook_resid_post',\n",
      " 'blocks.2.hook_resid_pre',\n",
      " 'blocks.2.ln1.hook_scale',\n",
      " 'blocks.2.ln1.hook_normalized',\n",
      " 'blocks.2.attn.hook_q',\n",
      " 'blocks.2.attn.hook_k',\n",
      " 'blocks.2.attn.hook_v',\n",
      " 'blocks.2.attn.hook_rot_q',\n",
      " 'blocks.2.attn.hook_rot_k',\n",
      " 'blocks.2.attn.hook_attn_scores',\n",
      " 'blocks.2.attn.hook_pattern',\n",
      " 'blocks.2.attn.hook_z',\n",
      " 'blocks.2.hook_attn_out',\n",
      " 'blocks.2.hook_resid_mid',\n",
      " 'blocks.2.ln2.hook_scale',\n",
      " 'blocks.2.ln2.hook_normalized',\n",
      " 'blocks.2.mlp.hook_pre',\n",
      " 'blocks.2.mlp.hook_pre_linear',\n",
      " 'blocks.2.mlp.hook_post',\n",
      " 'blocks.2.hook_mlp_out',\n",
      " 'blocks.2.hook_resid_post',\n",
      " 'blocks.3.hook_resid_pre',\n",
      " 'blocks.3.ln1.hook_scale',\n",
      " 'blocks.3.ln1.hook_normalized',\n",
      " 'blocks.3.attn.hook_q',\n",
      " 'blocks.3.attn.hook_k',\n",
      " 'blocks.3.attn.hook_v',\n",
      " 'blocks.3.attn.hook_rot_q',\n",
      " 'blocks.3.attn.hook_rot_k',\n",
      " 'blocks.3.attn.hook_attn_scores',\n",
      " 'blocks.3.attn.hook_pattern',\n",
      " 'blocks.3.attn.hook_z',\n",
      " 'blocks.3.hook_attn_out',\n",
      " 'blocks.3.hook_resid_mid',\n",
      " 'blocks.3.ln2.hook_scale',\n",
      " 'blocks.3.ln2.hook_normalized',\n",
      " 'blocks.3.mlp.hook_pre',\n",
      " 'blocks.3.mlp.hook_pre_linear',\n",
      " 'blocks.3.mlp.hook_post',\n",
      " 'blocks.3.hook_mlp_out',\n",
      " 'blocks.3.hook_resid_post',\n",
      " 'blocks.4.hook_resid_pre',\n",
      " 'blocks.4.ln1.hook_scale',\n",
      " 'blocks.4.ln1.hook_normalized',\n",
      " 'blocks.4.attn.hook_q',\n",
      " 'blocks.4.attn.hook_k',\n",
      " 'blocks.4.attn.hook_v',\n",
      " 'blocks.4.attn.hook_rot_q',\n",
      " 'blocks.4.attn.hook_rot_k',\n",
      " 'blocks.4.attn.hook_attn_scores',\n",
      " 'blocks.4.attn.hook_pattern',\n",
      " 'blocks.4.attn.hook_z',\n",
      " 'blocks.4.hook_attn_out',\n",
      " 'blocks.4.hook_resid_mid',\n",
      " 'blocks.4.ln2.hook_scale',\n",
      " 'blocks.4.ln2.hook_normalized',\n",
      " 'blocks.4.mlp.hook_pre',\n",
      " 'blocks.4.mlp.hook_pre_linear',\n",
      " 'blocks.4.mlp.hook_post',\n",
      " 'blocks.4.hook_mlp_out',\n",
      " 'blocks.4.hook_resid_post',\n",
      " 'blocks.5.hook_resid_pre',\n",
      " 'blocks.5.ln1.hook_scale',\n",
      " 'blocks.5.ln1.hook_normalized',\n",
      " 'blocks.5.attn.hook_q',\n",
      " 'blocks.5.attn.hook_k',\n",
      " 'blocks.5.attn.hook_v',\n",
      " 'blocks.5.attn.hook_rot_q',\n",
      " 'blocks.5.attn.hook_rot_k',\n",
      " 'blocks.5.attn.hook_attn_scores',\n",
      " 'blocks.5.attn.hook_pattern',\n",
      " 'blocks.5.attn.hook_z',\n",
      " 'blocks.5.hook_attn_out',\n",
      " 'blocks.5.hook_resid_mid',\n",
      " 'blocks.5.ln2.hook_scale',\n",
      " 'blocks.5.ln2.hook_normalized',\n",
      " 'blocks.5.mlp.hook_pre',\n",
      " 'blocks.5.mlp.hook_pre_linear',\n",
      " 'blocks.5.mlp.hook_post',\n",
      " 'blocks.5.hook_mlp_out',\n",
      " 'blocks.5.hook_resid_post',\n",
      " 'blocks.6.hook_resid_pre',\n",
      " 'blocks.6.ln1.hook_scale',\n",
      " 'blocks.6.ln1.hook_normalized',\n",
      " 'blocks.6.attn.hook_q',\n",
      " 'blocks.6.attn.hook_k',\n",
      " 'blocks.6.attn.hook_v',\n",
      " 'blocks.6.attn.hook_rot_q',\n",
      " 'blocks.6.attn.hook_rot_k',\n",
      " 'blocks.6.attn.hook_attn_scores',\n",
      " 'blocks.6.attn.hook_pattern',\n",
      " 'blocks.6.attn.hook_z',\n",
      " 'blocks.6.hook_attn_out',\n",
      " 'blocks.6.hook_resid_mid',\n",
      " 'blocks.6.ln2.hook_scale',\n",
      " 'blocks.6.ln2.hook_normalized',\n",
      " 'blocks.6.mlp.hook_pre',\n",
      " 'blocks.6.mlp.hook_pre_linear',\n",
      " 'blocks.6.mlp.hook_post',\n",
      " 'blocks.6.hook_mlp_out',\n",
      " 'blocks.6.hook_resid_post',\n",
      " 'blocks.7.hook_resid_pre',\n",
      " 'blocks.7.ln1.hook_scale',\n",
      " 'blocks.7.ln1.hook_normalized',\n",
      " 'blocks.7.attn.hook_q',\n",
      " 'blocks.7.attn.hook_k',\n",
      " 'blocks.7.attn.hook_v',\n",
      " 'blocks.7.attn.hook_rot_q',\n",
      " 'blocks.7.attn.hook_rot_k',\n",
      " 'blocks.7.attn.hook_attn_scores',\n",
      " 'blocks.7.attn.hook_pattern',\n",
      " 'blocks.7.attn.hook_z',\n",
      " 'blocks.7.hook_attn_out',\n",
      " 'blocks.7.hook_resid_mid',\n",
      " 'blocks.7.ln2.hook_scale',\n",
      " 'blocks.7.ln2.hook_normalized',\n",
      " 'blocks.7.mlp.hook_pre',\n",
      " 'blocks.7.mlp.hook_pre_linear',\n",
      " 'blocks.7.mlp.hook_post',\n",
      " 'blocks.7.hook_mlp_out',\n",
      " 'blocks.7.hook_resid_post',\n",
      " 'blocks.8.hook_resid_pre',\n",
      " 'blocks.8.ln1.hook_scale',\n",
      " 'blocks.8.ln1.hook_normalized',\n",
      " 'blocks.8.attn.hook_q',\n",
      " 'blocks.8.attn.hook_k',\n",
      " 'blocks.8.attn.hook_v',\n",
      " 'blocks.8.attn.hook_rot_q',\n",
      " 'blocks.8.attn.hook_rot_k',\n",
      " 'blocks.8.attn.hook_attn_scores',\n",
      " 'blocks.8.attn.hook_pattern',\n",
      " 'blocks.8.attn.hook_z',\n",
      " 'blocks.8.hook_attn_out',\n",
      " 'blocks.8.hook_resid_mid',\n",
      " 'blocks.8.ln2.hook_scale',\n",
      " 'blocks.8.ln2.hook_normalized',\n",
      " 'blocks.8.mlp.hook_pre',\n",
      " 'blocks.8.mlp.hook_pre_linear',\n",
      " 'blocks.8.mlp.hook_post',\n",
      " 'blocks.8.hook_mlp_out',\n",
      " 'blocks.8.hook_resid_post',\n",
      " 'blocks.9.hook_resid_pre',\n",
      " 'blocks.9.ln1.hook_scale',\n",
      " 'blocks.9.ln1.hook_normalized',\n",
      " 'blocks.9.attn.hook_q',\n",
      " 'blocks.9.attn.hook_k',\n",
      " 'blocks.9.attn.hook_v',\n",
      " 'blocks.9.attn.hook_rot_q',\n",
      " 'blocks.9.attn.hook_rot_k',\n",
      " 'blocks.9.attn.hook_attn_scores',\n",
      " 'blocks.9.attn.hook_pattern',\n",
      " 'blocks.9.attn.hook_z',\n",
      " 'blocks.9.hook_attn_out',\n",
      " 'blocks.9.hook_resid_mid',\n",
      " 'blocks.9.ln2.hook_scale',\n",
      " 'blocks.9.ln2.hook_normalized',\n",
      " 'blocks.9.mlp.hook_pre',\n",
      " 'blocks.9.mlp.hook_pre_linear',\n",
      " 'blocks.9.mlp.hook_post',\n",
      " 'blocks.9.hook_mlp_out',\n",
      " 'blocks.9.hook_resid_post',\n",
      " 'blocks.10.hook_resid_pre',\n",
      " 'blocks.10.ln1.hook_scale',\n",
      " 'blocks.10.ln1.hook_normalized',\n",
      " 'blocks.10.attn.hook_q',\n",
      " 'blocks.10.attn.hook_k',\n",
      " 'blocks.10.attn.hook_v',\n",
      " 'blocks.10.attn.hook_rot_q',\n",
      " 'blocks.10.attn.hook_rot_k',\n",
      " 'blocks.10.attn.hook_attn_scores',\n",
      " 'blocks.10.attn.hook_pattern',\n",
      " 'blocks.10.attn.hook_z',\n",
      " 'blocks.10.hook_attn_out',\n",
      " 'blocks.10.hook_resid_mid',\n",
      " 'blocks.10.ln2.hook_scale',\n",
      " 'blocks.10.ln2.hook_normalized',\n",
      " 'blocks.10.mlp.hook_pre',\n",
      " 'blocks.10.mlp.hook_pre_linear',\n",
      " 'blocks.10.mlp.hook_post',\n",
      " 'blocks.10.hook_mlp_out',\n",
      " 'blocks.10.hook_resid_post',\n",
      " 'blocks.11.hook_resid_pre',\n",
      " 'blocks.11.ln1.hook_scale',\n",
      " 'blocks.11.ln1.hook_normalized',\n",
      " 'blocks.11.attn.hook_q',\n",
      " 'blocks.11.attn.hook_k',\n",
      " 'blocks.11.attn.hook_v',\n",
      " 'blocks.11.attn.hook_rot_q',\n",
      " 'blocks.11.attn.hook_rot_k',\n",
      " 'blocks.11.attn.hook_attn_scores',\n",
      " 'blocks.11.attn.hook_pattern',\n",
      " 'blocks.11.attn.hook_z',\n",
      " 'blocks.11.hook_attn_out',\n",
      " 'blocks.11.hook_resid_mid',\n",
      " 'blocks.11.ln2.hook_scale',\n",
      " 'blocks.11.ln2.hook_normalized',\n",
      " 'blocks.11.mlp.hook_pre',\n",
      " 'blocks.11.mlp.hook_pre_linear',\n",
      " 'blocks.11.mlp.hook_post',\n",
      " 'blocks.11.hook_mlp_out',\n",
      " 'blocks.11.hook_resid_post',\n",
      " 'blocks.12.hook_resid_pre',\n",
      " 'blocks.12.ln1.hook_scale',\n",
      " 'blocks.12.ln1.hook_normalized',\n",
      " 'blocks.12.attn.hook_q',\n",
      " 'blocks.12.attn.hook_k',\n",
      " 'blocks.12.attn.hook_v',\n",
      " 'blocks.12.attn.hook_rot_q',\n",
      " 'blocks.12.attn.hook_rot_k',\n",
      " 'blocks.12.attn.hook_attn_scores',\n",
      " 'blocks.12.attn.hook_pattern',\n",
      " 'blocks.12.attn.hook_z',\n",
      " 'blocks.12.hook_attn_out',\n",
      " 'blocks.12.hook_resid_mid',\n",
      " 'blocks.12.ln2.hook_scale',\n",
      " 'blocks.12.ln2.hook_normalized',\n",
      " 'blocks.12.mlp.hook_pre',\n",
      " 'blocks.12.mlp.hook_pre_linear',\n",
      " 'blocks.12.mlp.hook_post',\n",
      " 'blocks.12.hook_mlp_out',\n",
      " 'blocks.12.hook_resid_post',\n",
      " 'blocks.13.hook_resid_pre',\n",
      " 'blocks.13.ln1.hook_scale',\n",
      " 'blocks.13.ln1.hook_normalized',\n",
      " 'blocks.13.attn.hook_q',\n",
      " 'blocks.13.attn.hook_k',\n",
      " 'blocks.13.attn.hook_v',\n",
      " 'blocks.13.attn.hook_rot_q',\n",
      " 'blocks.13.attn.hook_rot_k',\n",
      " 'blocks.13.attn.hook_attn_scores',\n",
      " 'blocks.13.attn.hook_pattern',\n",
      " 'blocks.13.attn.hook_z',\n",
      " 'blocks.13.hook_attn_out',\n",
      " 'blocks.13.hook_resid_mid',\n",
      " 'blocks.13.ln2.hook_scale',\n",
      " 'blocks.13.ln2.hook_normalized',\n",
      " 'blocks.13.mlp.hook_pre',\n",
      " 'blocks.13.mlp.hook_pre_linear',\n",
      " 'blocks.13.mlp.hook_post',\n",
      " 'blocks.13.hook_mlp_out',\n",
      " 'blocks.13.hook_resid_post',\n",
      " 'blocks.14.hook_resid_pre',\n",
      " 'blocks.14.ln1.hook_scale',\n",
      " 'blocks.14.ln1.hook_normalized',\n",
      " 'blocks.14.attn.hook_q',\n",
      " 'blocks.14.attn.hook_k',\n",
      " 'blocks.14.attn.hook_v',\n",
      " 'blocks.14.attn.hook_rot_q',\n",
      " 'blocks.14.attn.hook_rot_k',\n",
      " 'blocks.14.attn.hook_attn_scores',\n",
      " 'blocks.14.attn.hook_pattern',\n",
      " 'blocks.14.attn.hook_z',\n",
      " 'blocks.14.hook_attn_out',\n",
      " 'blocks.14.hook_resid_mid',\n",
      " 'blocks.14.ln2.hook_scale',\n",
      " 'blocks.14.ln2.hook_normalized',\n",
      " 'blocks.14.mlp.hook_pre',\n",
      " 'blocks.14.mlp.hook_pre_linear',\n",
      " 'blocks.14.mlp.hook_post',\n",
      " 'blocks.14.hook_mlp_out',\n",
      " 'blocks.14.hook_resid_post',\n",
      " 'blocks.15.hook_resid_pre',\n",
      " 'blocks.15.ln1.hook_scale',\n",
      " 'blocks.15.ln1.hook_normalized',\n",
      " 'blocks.15.attn.hook_q',\n",
      " 'blocks.15.attn.hook_k',\n",
      " 'blocks.15.attn.hook_v',\n",
      " 'blocks.15.attn.hook_rot_q',\n",
      " 'blocks.15.attn.hook_rot_k',\n",
      " 'blocks.15.attn.hook_attn_scores',\n",
      " 'blocks.15.attn.hook_pattern',\n",
      " 'blocks.15.attn.hook_z',\n",
      " 'blocks.15.hook_attn_out',\n",
      " 'blocks.15.hook_resid_mid',\n",
      " 'blocks.15.ln2.hook_scale',\n",
      " 'blocks.15.ln2.hook_normalized',\n",
      " 'blocks.15.mlp.hook_pre',\n",
      " 'blocks.15.mlp.hook_pre_linear',\n",
      " 'blocks.15.mlp.hook_post',\n",
      " 'blocks.15.hook_mlp_out',\n",
      " 'blocks.15.hook_resid_post',\n",
      " 'blocks.16.hook_resid_pre',\n",
      " 'blocks.16.ln1.hook_scale',\n",
      " 'blocks.16.ln1.hook_normalized',\n",
      " 'blocks.16.attn.hook_q',\n",
      " 'blocks.16.attn.hook_k',\n",
      " 'blocks.16.attn.hook_v',\n",
      " 'blocks.16.attn.hook_rot_q',\n",
      " 'blocks.16.attn.hook_rot_k',\n",
      " 'blocks.16.attn.hook_attn_scores',\n",
      " 'blocks.16.attn.hook_pattern',\n",
      " 'blocks.16.attn.hook_z',\n",
      " 'blocks.16.hook_attn_out',\n",
      " 'blocks.16.hook_resid_mid',\n",
      " 'blocks.16.ln2.hook_scale',\n",
      " 'blocks.16.ln2.hook_normalized',\n",
      " 'blocks.16.mlp.hook_pre',\n",
      " 'blocks.16.mlp.hook_pre_linear',\n",
      " 'blocks.16.mlp.hook_post',\n",
      " 'blocks.16.hook_mlp_out',\n",
      " 'blocks.16.hook_resid_post',\n",
      " 'blocks.17.hook_resid_pre',\n",
      " 'blocks.17.ln1.hook_scale',\n",
      " 'blocks.17.ln1.hook_normalized',\n",
      " 'blocks.17.attn.hook_q',\n",
      " 'blocks.17.attn.hook_k',\n",
      " 'blocks.17.attn.hook_v',\n",
      " 'blocks.17.attn.hook_rot_q',\n",
      " 'blocks.17.attn.hook_rot_k',\n",
      " 'blocks.17.attn.hook_attn_scores',\n",
      " 'blocks.17.attn.hook_pattern',\n",
      " 'blocks.17.attn.hook_z',\n",
      " 'blocks.17.hook_attn_out',\n",
      " 'blocks.17.hook_resid_mid',\n",
      " 'blocks.17.ln2.hook_scale',\n",
      " 'blocks.17.ln2.hook_normalized',\n",
      " 'blocks.17.mlp.hook_pre',\n",
      " 'blocks.17.mlp.hook_pre_linear',\n",
      " 'blocks.17.mlp.hook_post',\n",
      " 'blocks.17.hook_mlp_out',\n",
      " 'blocks.17.hook_resid_post',\n",
      " 'blocks.18.hook_resid_pre',\n",
      " 'blocks.18.ln1.hook_scale',\n",
      " 'blocks.18.ln1.hook_normalized',\n",
      " 'blocks.18.attn.hook_q',\n",
      " 'blocks.18.attn.hook_k',\n",
      " 'blocks.18.attn.hook_v',\n",
      " 'blocks.18.attn.hook_rot_q',\n",
      " 'blocks.18.attn.hook_rot_k',\n",
      " 'blocks.18.attn.hook_attn_scores',\n",
      " 'blocks.18.attn.hook_pattern',\n",
      " 'blocks.18.attn.hook_z',\n",
      " 'blocks.18.hook_attn_out',\n",
      " 'blocks.18.hook_resid_mid',\n",
      " 'blocks.18.ln2.hook_scale',\n",
      " 'blocks.18.ln2.hook_normalized',\n",
      " 'blocks.18.mlp.hook_pre',\n",
      " 'blocks.18.mlp.hook_pre_linear',\n",
      " 'blocks.18.mlp.hook_post',\n",
      " 'blocks.18.hook_mlp_out',\n",
      " 'blocks.18.hook_resid_post',\n",
      " 'blocks.19.hook_resid_pre',\n",
      " 'blocks.19.ln1.hook_scale',\n",
      " 'blocks.19.ln1.hook_normalized',\n",
      " 'blocks.19.attn.hook_q',\n",
      " 'blocks.19.attn.hook_k',\n",
      " 'blocks.19.attn.hook_v',\n",
      " 'blocks.19.attn.hook_rot_q',\n",
      " 'blocks.19.attn.hook_rot_k',\n",
      " 'blocks.19.attn.hook_attn_scores',\n",
      " 'blocks.19.attn.hook_pattern',\n",
      " 'blocks.19.attn.hook_z',\n",
      " 'blocks.19.hook_attn_out',\n",
      " 'blocks.19.hook_resid_mid',\n",
      " 'blocks.19.ln2.hook_scale',\n",
      " 'blocks.19.ln2.hook_normalized',\n",
      " 'blocks.19.mlp.hook_pre',\n",
      " 'blocks.19.mlp.hook_pre_linear',\n",
      " 'blocks.19.mlp.hook_post',\n",
      " 'blocks.19.hook_mlp_out',\n",
      " 'blocks.19.hook_resid_post',\n",
      " 'blocks.20.hook_resid_pre',\n",
      " 'blocks.20.ln1.hook_scale',\n",
      " 'blocks.20.ln1.hook_normalized',\n",
      " 'blocks.20.attn.hook_q',\n",
      " 'blocks.20.attn.hook_k',\n",
      " 'blocks.20.attn.hook_v',\n",
      " 'blocks.20.attn.hook_rot_q',\n",
      " 'blocks.20.attn.hook_rot_k',\n",
      " 'blocks.20.attn.hook_attn_scores',\n",
      " 'blocks.20.attn.hook_pattern',\n",
      " 'blocks.20.attn.hook_z',\n",
      " 'blocks.20.hook_attn_out',\n",
      " 'blocks.20.hook_resid_mid',\n",
      " 'blocks.20.ln2.hook_scale',\n",
      " 'blocks.20.ln2.hook_normalized',\n",
      " 'blocks.20.mlp.hook_pre',\n",
      " 'blocks.20.mlp.hook_pre_linear',\n",
      " 'blocks.20.mlp.hook_post',\n",
      " 'blocks.20.hook_mlp_out',\n",
      " 'blocks.20.hook_resid_post',\n",
      " 'blocks.21.hook_resid_pre',\n",
      " 'blocks.21.ln1.hook_scale',\n",
      " 'blocks.21.ln1.hook_normalized',\n",
      " 'blocks.21.attn.hook_q',\n",
      " 'blocks.21.attn.hook_k',\n",
      " 'blocks.21.attn.hook_v',\n",
      " 'blocks.21.attn.hook_rot_q',\n",
      " 'blocks.21.attn.hook_rot_k',\n",
      " 'blocks.21.attn.hook_attn_scores',\n",
      " 'blocks.21.attn.hook_pattern',\n",
      " 'blocks.21.attn.hook_z',\n",
      " 'blocks.21.hook_attn_out',\n",
      " 'blocks.21.hook_resid_mid',\n",
      " 'blocks.21.ln2.hook_scale',\n",
      " 'blocks.21.ln2.hook_normalized',\n",
      " 'blocks.21.mlp.hook_pre',\n",
      " 'blocks.21.mlp.hook_pre_linear',\n",
      " 'blocks.21.mlp.hook_post',\n",
      " 'blocks.21.hook_mlp_out',\n",
      " 'blocks.21.hook_resid_post',\n",
      " 'blocks.22.hook_resid_pre',\n",
      " 'blocks.22.ln1.hook_scale',\n",
      " 'blocks.22.ln1.hook_normalized',\n",
      " 'blocks.22.attn.hook_q',\n",
      " 'blocks.22.attn.hook_k',\n",
      " 'blocks.22.attn.hook_v',\n",
      " 'blocks.22.attn.hook_rot_q',\n",
      " 'blocks.22.attn.hook_rot_k',\n",
      " 'blocks.22.attn.hook_attn_scores',\n",
      " 'blocks.22.attn.hook_pattern',\n",
      " 'blocks.22.attn.hook_z',\n",
      " 'blocks.22.hook_attn_out',\n",
      " 'blocks.22.hook_resid_mid',\n",
      " 'blocks.22.ln2.hook_scale',\n",
      " 'blocks.22.ln2.hook_normalized',\n",
      " 'blocks.22.mlp.hook_pre',\n",
      " 'blocks.22.mlp.hook_pre_linear',\n",
      " 'blocks.22.mlp.hook_post',\n",
      " 'blocks.22.hook_mlp_out',\n",
      " 'blocks.22.hook_resid_post',\n",
      " 'blocks.23.hook_resid_pre',\n",
      " 'blocks.23.ln1.hook_scale',\n",
      " 'blocks.23.ln1.hook_normalized',\n",
      " 'blocks.23.attn.hook_q',\n",
      " 'blocks.23.attn.hook_k',\n",
      " 'blocks.23.attn.hook_v',\n",
      " 'blocks.23.attn.hook_rot_q',\n",
      " 'blocks.23.attn.hook_rot_k',\n",
      " 'blocks.23.attn.hook_attn_scores',\n",
      " 'blocks.23.attn.hook_pattern',\n",
      " 'blocks.23.attn.hook_z',\n",
      " 'blocks.23.hook_attn_out',\n",
      " 'blocks.23.hook_resid_mid',\n",
      " 'blocks.23.ln2.hook_scale',\n",
      " 'blocks.23.ln2.hook_normalized',\n",
      " 'blocks.23.mlp.hook_pre',\n",
      " 'blocks.23.mlp.hook_pre_linear',\n",
      " 'blocks.23.mlp.hook_post',\n",
      " 'blocks.23.hook_mlp_out',\n",
      " 'blocks.23.hook_resid_post',\n",
      " 'blocks.24.hook_resid_pre',\n",
      " 'blocks.24.ln1.hook_scale',\n",
      " 'blocks.24.ln1.hook_normalized',\n",
      " 'blocks.24.attn.hook_q',\n",
      " 'blocks.24.attn.hook_k',\n",
      " 'blocks.24.attn.hook_v',\n",
      " 'blocks.24.attn.hook_rot_q',\n",
      " 'blocks.24.attn.hook_rot_k',\n",
      " 'blocks.24.attn.hook_attn_scores',\n",
      " 'blocks.24.attn.hook_pattern',\n",
      " 'blocks.24.attn.hook_z',\n",
      " 'blocks.24.hook_attn_out',\n",
      " 'blocks.24.hook_resid_mid',\n",
      " 'blocks.24.ln2.hook_scale',\n",
      " 'blocks.24.ln2.hook_normalized',\n",
      " 'blocks.24.mlp.hook_pre',\n",
      " 'blocks.24.mlp.hook_pre_linear',\n",
      " 'blocks.24.mlp.hook_post',\n",
      " 'blocks.24.hook_mlp_out',\n",
      " 'blocks.24.hook_resid_post',\n",
      " 'blocks.25.hook_resid_pre',\n",
      " 'blocks.25.ln1.hook_scale',\n",
      " 'blocks.25.ln1.hook_normalized',\n",
      " 'blocks.25.attn.hook_q',\n",
      " 'blocks.25.attn.hook_k',\n",
      " 'blocks.25.attn.hook_v',\n",
      " 'blocks.25.attn.hook_rot_q',\n",
      " 'blocks.25.attn.hook_rot_k',\n",
      " 'blocks.25.attn.hook_attn_scores',\n",
      " 'blocks.25.attn.hook_pattern',\n",
      " 'blocks.25.attn.hook_z',\n",
      " 'blocks.25.hook_attn_out',\n",
      " 'blocks.25.hook_resid_mid',\n",
      " 'blocks.25.ln2.hook_scale',\n",
      " 'blocks.25.ln2.hook_normalized',\n",
      " 'blocks.25.mlp.hook_pre',\n",
      " 'blocks.25.mlp.hook_pre_linear',\n",
      " 'blocks.25.mlp.hook_post',\n",
      " 'blocks.25.hook_mlp_out',\n",
      " 'blocks.25.hook_resid_post',\n",
      " 'blocks.26.hook_resid_pre',\n",
      " 'blocks.26.ln1.hook_scale',\n",
      " 'blocks.26.ln1.hook_normalized',\n",
      " 'blocks.26.attn.hook_q',\n",
      " 'blocks.26.attn.hook_k',\n",
      " 'blocks.26.attn.hook_v',\n",
      " 'blocks.26.attn.hook_rot_q',\n",
      " 'blocks.26.attn.hook_rot_k',\n",
      " 'blocks.26.attn.hook_attn_scores',\n",
      " 'blocks.26.attn.hook_pattern',\n",
      " 'blocks.26.attn.hook_z',\n",
      " 'blocks.26.hook_attn_out',\n",
      " 'blocks.26.hook_resid_mid',\n",
      " 'blocks.26.ln2.hook_scale',\n",
      " 'blocks.26.ln2.hook_normalized',\n",
      " 'blocks.26.mlp.hook_pre',\n",
      " 'blocks.26.mlp.hook_pre_linear',\n",
      " 'blocks.26.mlp.hook_post',\n",
      " 'blocks.26.hook_mlp_out',\n",
      " 'blocks.26.hook_resid_post',\n",
      " 'blocks.27.hook_resid_pre',\n",
      " 'blocks.27.ln1.hook_scale',\n",
      " 'blocks.27.ln1.hook_normalized',\n",
      " 'blocks.27.attn.hook_q',\n",
      " 'blocks.27.attn.hook_k',\n",
      " 'blocks.27.attn.hook_v',\n",
      " 'blocks.27.attn.hook_rot_q',\n",
      " 'blocks.27.attn.hook_rot_k',\n",
      " 'blocks.27.attn.hook_attn_scores',\n",
      " 'blocks.27.attn.hook_pattern',\n",
      " 'blocks.27.attn.hook_z',\n",
      " 'blocks.27.hook_attn_out',\n",
      " 'blocks.27.hook_resid_mid',\n",
      " 'blocks.27.ln2.hook_scale',\n",
      " 'blocks.27.ln2.hook_normalized',\n",
      " 'blocks.27.mlp.hook_pre',\n",
      " 'blocks.27.mlp.hook_pre_linear',\n",
      " 'blocks.27.mlp.hook_post',\n",
      " 'blocks.27.hook_mlp_out',\n",
      " 'blocks.27.hook_resid_post',\n",
      " 'blocks.28.hook_resid_pre',\n",
      " 'blocks.28.ln1.hook_scale',\n",
      " 'blocks.28.ln1.hook_normalized',\n",
      " 'blocks.28.attn.hook_q',\n",
      " 'blocks.28.attn.hook_k',\n",
      " 'blocks.28.attn.hook_v',\n",
      " 'blocks.28.attn.hook_rot_q',\n",
      " 'blocks.28.attn.hook_rot_k',\n",
      " 'blocks.28.attn.hook_attn_scores',\n",
      " 'blocks.28.attn.hook_pattern',\n",
      " 'blocks.28.attn.hook_z',\n",
      " 'blocks.28.hook_attn_out',\n",
      " 'blocks.28.hook_resid_mid',\n",
      " 'blocks.28.ln2.hook_scale',\n",
      " 'blocks.28.ln2.hook_normalized',\n",
      " 'blocks.28.mlp.hook_pre',\n",
      " 'blocks.28.mlp.hook_pre_linear',\n",
      " 'blocks.28.mlp.hook_post',\n",
      " 'blocks.28.hook_mlp_out',\n",
      " 'blocks.28.hook_resid_post',\n",
      " 'blocks.29.hook_resid_pre',\n",
      " 'blocks.29.ln1.hook_scale',\n",
      " 'blocks.29.ln1.hook_normalized',\n",
      " 'blocks.29.attn.hook_q',\n",
      " 'blocks.29.attn.hook_k',\n",
      " 'blocks.29.attn.hook_v',\n",
      " 'blocks.29.attn.hook_rot_q',\n",
      " 'blocks.29.attn.hook_rot_k',\n",
      " 'blocks.29.attn.hook_attn_scores',\n",
      " 'blocks.29.attn.hook_pattern',\n",
      " 'blocks.29.attn.hook_z',\n",
      " 'blocks.29.hook_attn_out',\n",
      " 'blocks.29.hook_resid_mid',\n",
      " 'blocks.29.ln2.hook_scale',\n",
      " 'blocks.29.ln2.hook_normalized',\n",
      " 'blocks.29.mlp.hook_pre',\n",
      " 'blocks.29.mlp.hook_pre_linear',\n",
      " 'blocks.29.mlp.hook_post',\n",
      " 'blocks.29.hook_mlp_out',\n",
      " 'blocks.29.hook_resid_post',\n",
      " 'blocks.30.hook_resid_pre',\n",
      " 'blocks.30.ln1.hook_scale',\n",
      " 'blocks.30.ln1.hook_normalized',\n",
      " 'blocks.30.attn.hook_q',\n",
      " 'blocks.30.attn.hook_k',\n",
      " 'blocks.30.attn.hook_v',\n",
      " 'blocks.30.attn.hook_rot_q',\n",
      " 'blocks.30.attn.hook_rot_k',\n",
      " 'blocks.30.attn.hook_attn_scores',\n",
      " 'blocks.30.attn.hook_pattern',\n",
      " 'blocks.30.attn.hook_z',\n",
      " 'blocks.30.hook_attn_out',\n",
      " 'blocks.30.hook_resid_mid',\n",
      " 'blocks.30.ln2.hook_scale',\n",
      " 'blocks.30.ln2.hook_normalized',\n",
      " 'blocks.30.mlp.hook_pre',\n",
      " 'blocks.30.mlp.hook_pre_linear',\n",
      " 'blocks.30.mlp.hook_post',\n",
      " 'blocks.30.hook_mlp_out',\n",
      " 'blocks.30.hook_resid_post',\n",
      " 'blocks.31.hook_resid_pre',\n",
      " 'blocks.31.ln1.hook_scale',\n",
      " 'blocks.31.ln1.hook_normalized',\n",
      " 'blocks.31.attn.hook_q',\n",
      " 'blocks.31.attn.hook_k',\n",
      " 'blocks.31.attn.hook_v',\n",
      " 'blocks.31.attn.hook_rot_q',\n",
      " 'blocks.31.attn.hook_rot_k',\n",
      " 'blocks.31.attn.hook_attn_scores',\n",
      " 'blocks.31.attn.hook_pattern',\n",
      " 'blocks.31.attn.hook_z',\n",
      " 'blocks.31.hook_attn_out',\n",
      " 'blocks.31.hook_resid_mid',\n",
      " 'blocks.31.ln2.hook_scale',\n",
      " 'blocks.31.ln2.hook_normalized',\n",
      " 'blocks.31.mlp.hook_pre',\n",
      " 'blocks.31.mlp.hook_pre_linear',\n",
      " 'blocks.31.mlp.hook_post',\n",
      " 'blocks.31.hook_mlp_out',\n",
      " 'blocks.31.hook_resid_post',\n",
      " 'ln_final.hook_scale',\n",
      " 'ln_final.hook_normalized']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(paraphrased_cache['blocks.0.hook_resid_post'][:,-1,:].squeeze().shape)\n",
    "pprint(list(paraphrased_cache.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "analyze_list = [f'blocks.{i}.hook_resid_post' for i in range(32)]\n",
    "cos_sim = []\n",
    "for name in analyze_list:\n",
    "    cos_similarity = F.cosine_similarity(original_cache[name][:,-1,:].squeeze(), paraphrased_cache[name][:,-1,:].squeeze(), dim=-1)\n",
    "    cos_sim.append(cos_similarity)\n",
    "\n",
    "comparison_cos_sim = []\n",
    "for name in analyze_list:\n",
    "    cos_similarity = F.cosine_similarity(original_cache[name][:,-1,:].squeeze(), comparison_cache[name][:,-1,:].squeeze(), dim=-1)\n",
    "    comparison_cos_sim.append(cos_similarity)\n",
    "\n",
    "x_labels = list(range(32))\n",
    "# plt.plot(x_labels, cos_sim)\n",
    "# plt.xlabel('X Label')\n",
    "# plt.ylabel('Cosine Similarity')\n",
    "# plt.title('Cosine Similarity Plot')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(x_labels, comparison_cos_sim)\n",
    "# plt.xlabel('X Label')\n",
    "# plt.ylabel('Cosine Similarity')\n",
    "# plt.title('Cosine Similarity Plot')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_labels, cos_sim, label='Cosine Similarity', color='blue')\n",
    "plt.plot(x_labels, comparison_cos_sim, label='Comparison', color='orange')\n",
    "\n",
    "plt.xlabel('X Label')\n",
    "plt.ylabel('Cosine Similarity')\n",
    "plt.title('Cosine Similarity Plot')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
